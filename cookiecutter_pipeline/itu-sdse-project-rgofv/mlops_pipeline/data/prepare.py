from pathlib import Path
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import joblib

from .io import write_any


def create_dummy_cols(df, col):
    '''
    Create one-hot encoding columns in the data.

    Input:
        df = a pandas dataframe
        col = string specifying the column to work on

    Output:
        new_df = an updated pandas dataframe, with the column changed.

    '''
    df_dummies = pd.get_dummies(df[col], prefix=col, drop_first=True)
    new_df = pd.concat([df, df_dummies], axis=1)
    new_df = new_df.drop(col, axis=1)
    return new_df


def load_and_prepare_data(data_gold_path: Path, out_dir: Path, scaler_path: Path, test_size: float = 0.15, random_state: int = 42, printing: bool=False):
    data = pd.read_csv(data_gold_path)
    if printing:
        print(f"[prepare.py] Training data length: {len(data)}")
        print(f"[prepare.py] Columns: {list(data.columns)[:10]}...")


    ## Drop ID/Leak columns if present
    drop_cols = [c for c in ["lead_id", "customer_code", "date_part"] if c in data.columns]
    if drop_cols:
        data = data.drop(columns=drop_cols)
        #data = data.drop([c], axis=1)
        if printing:
            print(f"[prepare.py] dropped Columns {drop_cols}")

    # Categorical handling
    if "onboarding" not in data.columns:
        raise ValueError("CRITICAL ERROR: 'onboarding' column is MISSING from input data in prepare.py!")
        
    cat_cols = [c for c in ["customer_group", "onboarding", "bin_source", "source"] if c in data.columns]
    cat_vars = data[cat_cols].copy()
    other_vars = data.drop(cat_cols, axis=1).copy()

    for col in cat_vars.columns:
        # Force onboarding to boolean to generate 'onboarding_True' dummy
        # This aligns with the remote validator which expects/produces onboarding_True
        if col == "onboarding":
             cat_vars[col] = cat_vars[col].astype(bool)
             # Explicitly set categories to ensure 'True' category exists even if data is all False
             cat_vars[col] = cat_vars[col].astype(pd.CategoricalDtype(categories=[False, True], ordered=False))
        
        cat_vars[col] = cat_vars[col].astype("category")
        cat_vars = create_dummy_cols(cat_vars, col)

    data = pd.concat([other_vars, cat_vars], axis=1)

    # Ensure numeric values
    for col in data.columns:
        #data[col] = data[col].astype("float64")
        # target can be int/bool; keep it numeric-friendly too
        data[col] = pd.to_numeric(data[col], errors="coerce")

        if printing:
            print(f"[prepare.py] Changed column {col} to float")

    y = data["lead_indicator"]
    X = data.drop(["lead_indicator"], axis=1)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, random_state=random_state, test_size=test_size, stratify=y
    )



    numeric_cols = X.select_dtypes(include=["float64", "int64"]).columns
    #non_numeric_cols = X.columns.difference(numeric_cols)

    # Let's create our MinMaxScaler here:
    scaler = MinMaxScaler()
    scaler.fit(X_train[numeric_cols])

    # We copy all data from the original X, then transform with the fitted scaler.
    X_train_scaled = X_train.copy()
    X_train_scaled[numeric_cols] = scaler.transform(X_train[numeric_cols])

    X_test_scaled = X_test.copy()
    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])


    joblib.dump(value=scaler, filename=scaler_path)

    out_dir.mkdir(parents=True, exist_ok=True)

    # Write FOUR separate files
    X_train_path = write_any(X_train_scaled, out_dir / "X_train.csv")
    y_train_path = write_any(y_train.to_frame(name="lead_indicator"), out_dir / "y_train.csv")
    X_test_path  = write_any(X_test_scaled,  out_dir / "X_test.csv")
    y_test_path  = write_any(y_test.to_frame(name="lead_indicator"),  out_dir / "y_test.csv")

    if printing:
        print(f"[prepare] Saved:")
        print(f"  - {X_train_path}")
        print(f"  - {y_train_path}")
        print(f"  - {X_test_path}")
        print(f"  - {y_test_path}")
        print(f"[prepare] Shapes: X_train={X_train_scaled.shape}, y_train={y_train.shape}, "
              f"X_test={X_test_scaled.shape}, y_test={y_test.shape}")


    return {
        "X_train": X_train_path,
        "y_train": y_train_path,
        "X_test": X_test_path,
        "y_test": y_test_path,
    }